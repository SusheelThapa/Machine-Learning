{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "pcW-G5R0V9NT"
      ],
      "authorship_tag": "ABX9TyNuH5VP2LhlB1wvxvtSmh6V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SusheelThapa/ML-From-Scratch/blob/linearRegression/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "rhej0ZPY9HaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm for Linear Regression\n",
        "\n",
        "### Training\n",
        "- Initialize *weight* as zero\n",
        "- Initialzie *bias* as zero\n",
        "<br/>\n",
        "\n",
        "**Given a data point**\n",
        "- Predict result by using ***`y_hat = wx+b`***\n",
        "- Calculate ***mean_squared_error***\n",
        "- Use ***gradient descent*** to figure out new weight and bias values\n",
        "- Repeat n times\n",
        "\n",
        "### Updating the parameters\n",
        "\n",
        "***`w = w- learning_rate * dj_dw`***\n",
        "\n",
        "***`b = b- learning_rate * dj_db`***\n",
        "\n",
        "### Testing\n",
        "\n",
        "Given a data point\n",
        "- Put in the values from the data points into the equation ***`y_hat = wx+b`***\n",
        "\n"
      ],
      "metadata": {
        "id": "gmI5GZJy_U08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding the above algorithms"
      ],
      "metadata": {
        "id": "_8vcC_wGU3YJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing necessary modules"
      ],
      "metadata": {
        "id": "X1J2Schz9WnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9ioMNUOK9OgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing the fit function"
      ],
      "metadata": {
        "id": "uwgTPWqEAtf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(X,y,learning_rate,number_of_iterations):\n",
        "    # Extracting the number of samples and features\n",
        "    n_samples,n_features = X.shape\n",
        "\n",
        "    # Initialize weights and bias with zeros\n",
        "    weights = np.zeros(n_features)\n",
        "    bias = 0\n",
        "\n",
        "    #Repeating for n times\n",
        "    for i in range(number_of_iterations):\n",
        "        # w1*x1 + w2*x2 +...wn*xn\n",
        "        y_pred = np.dot(X,weights) + bias\n",
        "\n",
        "        # Calculating partial derivative of cost function wrt to w and b\n",
        "        dj_dw = (1/n_samples)*np.dot(X.T,(y_pred -y))\n",
        "        dj_db = (1/n_samples)* np.sum(y_pred- y)\n",
        "\n",
        "        # Updating the value of w and b\n",
        "        weights = weights - learning_rate * dj_dw\n",
        "        bias = bias - learning_rate *dj_db\n",
        "    \n",
        "    return weights, bias\n"
      ],
      "metadata": {
        "id": "PvdghajhAwsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing the predict function"
      ],
      "metadata": {
        "id": "c89odxR9Exux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X,W,b):\n",
        "    y_pred = np.dot(X,W) + b\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "TQUSL2HXCWBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Scaling of data "
      ],
      "metadata": {
        "id": "q_Zvei6kOVSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaleData(X):\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    for i in range(n_features):\n",
        "        max_x= X[:,i].max()\n",
        "        X[:,i] = np.divide(X[:,i],max_x)\n",
        "    return X"
      ],
      "metadata": {
        "id": "DVWkjl6dQm_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating mean sqaure error"
      ],
      "metadata": {
        "id": "8uV_Jg8ycB7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_pred, y):\n",
        "    return np.mean((y - y_pred)**2)"
      ],
      "metadata": {
        "id": "muvS98vWcFDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model with one feature dataset"
      ],
      "metadata": {
        "id": "tfm4M1IRVcQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the datasets"
      ],
      "metadata": {
        "id": "3bMpZ8l_FF4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "\n",
        "X,y = datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=4)\n",
        "X_train, X_test,y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1234)"
      ],
      "metadata": {
        "id": "yTxHWVFWFIB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ploting the dataset without feature scaling"
      ],
      "metadata": {
        "id": "61amnEAPFqNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:,0],y,color='r',marker='X',s=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "amhec8bWFkkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling the data"
      ],
      "metadata": {
        "id": "reZTnsx3Vmga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = scaleData(X_train)\n",
        "X_test = scaleData(X_test)"
      ],
      "metadata": {
        "id": "VJtTqw2mVosl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting the data after feature scaling"
      ],
      "metadata": {
        "id": "MfU6RDx0SJJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_train[:,0],y_train,color='r',marker='X',s=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xY4mMColSM-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "zghueWdZGQyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W,b = fit(X_train,y_train,0.1,10000)"
      ],
      "metadata": {
        "id": "8zruMEF9F9xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model"
      ],
      "metadata": {
        "id": "MDswJJwXHUt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(X_test,W,b)"
      ],
      "metadata": {
        "id": "qVJM0SABHPKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ploting the line"
      ],
      "metadata": {
        "id": "pcW-G5R0V9NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(X_test,y_pred,linewidth=3,color='black',label='Prediction')\n",
        "plt.scatter(X_train,y_train,color='r',marker='X',s=10,label='Training Data')\n",
        "plt.scatter(X_test,y_test,color='b',marker='o',s=10 , label=\"Testing Data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zWUut9NcHmG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating **mean squared error**"
      ],
      "metadata": {
        "id": "1AWi2IbzJgHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error = mse(y_pred,y_test)\n",
        "print(mean_squared_error)"
      ],
      "metadata": {
        "id": "NMcbQYoyH1UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model with more than one feature dataset"
      ],
      "metadata": {
        "id": "uWpnYY-IWN4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the datasets\n"
      ],
      "metadata": {
        "id": "I4E6y7ceaDSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('house_price.xlsx')\n",
        "\n",
        "# Seperating the X and y from the dataset\n",
        "X = data.loc[:,[\n",
        "    'X1 transaction date',\n",
        "    'X2 house age',\n",
        "    'X3 distance to the nearest MRT station',\n",
        "    'X4 number of convenience stores',\n",
        "    'X5 latitude',\n",
        "    'X6 longitude']]\n",
        "\n",
        "y = data.loc[:,'Y house price of unit area']\n",
        "\n",
        "# Converting the data into numpy array\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "# Creating testing and training data\n",
        "X_train = X[:350]\n",
        "X_test = X[351:]\n",
        "y_train = y[:350]\n",
        "y_test = y[351:]"
      ],
      "metadata": {
        "id": "gUnzX3fzXbOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling the data"
      ],
      "metadata": {
        "id": "wsrCwsCcappe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = scaleData(X_train)\n",
        "X_test = scaleData(X_test)"
      ],
      "metadata": {
        "id": "bwpkGNi0an4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ploting the dataset with individual features"
      ],
      "metadata": {
        "id": "qwA1wyr_dL4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, n_features = X_train.shape\n",
        "\n",
        "customize = {\n",
        "        \"title\" : ['Transaction Date',\n",
        "         'House age',\n",
        "         'Distance to the nearest MRT',\n",
        "         'Number of convenience store',\n",
        "         'Latitude',\n",
        "         'Longitude'],\n",
        "        \"color\":['red',\"blue\",'orange','lightgreen',\"coral\",\"brown\"],\n",
        "                }\n",
        "\n",
        "\n",
        "for i in range(n_features):\n",
        "    plt.scatter(X_train[:,i],y_train,color=customize[\"color\"][i],marker='o',s=20)\n",
        "    plt.title(customize[\"title\"][i])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iLhLOw63dRNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "QDJjfnKobfrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W,b = fit(X_train,y_train,0.01,10000)"
      ],
      "metadata": {
        "id": "RQrxOtjmbkXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting the price of house"
      ],
      "metadata": {
        "id": "iHaQ62dPbtyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(X_test,W,b)"
      ],
      "metadata": {
        "id": "iFgn6SQ_bsXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating mean square error"
      ],
      "metadata": {
        "id": "MgUsFf79b8IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error = mse(y_pred, y_test)\n",
        "print(mean_squared_error)"
      ],
      "metadata": {
        "id": "xj59LJEGb7RT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}